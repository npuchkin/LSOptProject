\documentclass[10pt]{beamer}
\usepackage[cp1251]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{amsmath,mathrsfs,mathtext}
\usepackage{graphicx, epsfig}
\usepackage{array}
\usepackage{cmap}
\usepackage{tikz}
\usetikzlibrary{positioning,shadows,arrows,trees,shapes,fit}
\usepackage{xcolor}
\usepackage[noend]{algorithmic}
\usetikzlibrary{calc,intersections}
\usetheme{Rochester}
\usecolortheme{sidebartab}
\DeclareMathOperator{\tr}{tr}
\setbeamertemplate{caption}{\raggedright\insertcaption\par}

\newcommand\undermat[2]{%
  \makebox[0pt][l]{$\smash{\underbrace{\phantom{%
    \begin{matrix}#2\end{matrix}}}_{\text{$#1$}}}$}#2}
\newcommand{\argmin}{\mathop{\mathrm{argmin}}}

\definecolor{beamer@blendedblue}{RGB}{0,0,200}


%----------------------------------------------------------------------------------------------------------


\title
{Combinatorial optimization: Max-Cut, Min UnCut and Sparsest Cut Problems}
\author[M.~Danilova, N.~Puchkin, A.~Shilova]{\large Marina~Danilova, Nikita~Puchkin, 
Alena~Shilova}
\institute[Skoltech]{\textsc{Skolkovo Institute of Science and Technology}}
\date{\footnotesize{March 13, 2017}}

\begin{document}

\AtBeginSection[]
{
\begin{frame}{Outline}
\tableofcontents[
currentsection,
sectionstyle=show/shaded,
subsectionstyle=show/show/shaded
]
\end{frame}
}

\begin{frame}
    \titlepage
\end{frame}


\section{Combinatorial Optimization}

	\subsection{Max-Cut}
	
		\begin{frame}
			\frametitle{Max-Cut Problem}
			
			Given an undirected weighted graph $G = (V, E, W)$, where
			\begin{gather*}
				V  = \{ 1, \dots, n \} \text{ -- set of vertices} \\
				E \subseteq V \times V \text{ -- set of edges} \\
				W : E \rightarrow \mathbb R \text{ -- weights} \\
			\end{gather*}
			One wants to find a partition $f : V \rightarrow \{0, 1\}$ in order to maximize 
			the sum of edges in the cut:
			\[
				\sum\limits_{(i, j) \in E : f(i) \neq f(j)} w_{ij} \rightarrow \max,
			\]
			where $w_{ij}$ stands for weight of the edge $(i, j)$.
					
			
		\end{frame}
		
	\subsection{Min UnCut}
	
		\begin{frame}
			\frametitle{Min UnCut Problem}
			
			Given an undirected weighted graph $G = (V, E, W)$, one wants to find a 
			partition $f : \{ 
			0, 1 \}$ in order to minimize the sum of edges out of the cut:
			\[
				\sum\limits_{(i, j) \in E : f(i) = f(j)} w_{ij} \rightarrow \min
			\]
			
			\textsc{Remark.} Let $Opt( MUC )$ and $Opt( MC )$ stand for 
			optimal solutions of Min UnCut and Max-Cut problems respectively.
			Then it holds
			\[
				Opt( MUC ) + Opt( MC ) = \sum\limits_{(i, j) \in E} w_{ij}
			\]
		\end{frame}
		
	\subsection{Sparsest Cut}
	
		\begin{frame}
			\frametitle{Sparsest Cut Problem}
			
			Given an undirected weighted graph $G = (V, E$ and a capacity function $c 
			: E \rightarrow \mathbb R_+$.
			Also given a set of demand pairs $(s_1, t_1), (s_2, t_2), \dots, (s_k, t_k)$ and 
			demand values $d_1, d_2, \dots, d_k$.
			One wants to find a set $E' \subseteq E$ minimizing
			\[
				\frac{c(E') }{ D(E') } \rightarrow \min,
			\]
			where
			\begin{gather*}
				c(f) = \sum\limits_{(i, j) \in E'} c_{ij} \\
				D(f) = \sum\limits_{i : (s_i, t_i) \text{ are separated by } E'} d_i
			\end{gather*}
			
		\end{frame}

\section{Approaches}

	\begin{frame}
		\frametitle{}
		
		Max-Cut, Min UnCut and Sparsest Cut problems are NP-hard
		
		\pause
		\vspace{0.5in}
		
		Approaches:
		\begin{itemize}
			\item Use naive algorithm of discrete optimization
			\item Use convex relaxations
		\end{itemize}
	\end{frame}

	\subsection{Naive Algorithm}

	\begin{frame}
		\frametitle{Greedy algorithm}
		
		{\Large Idea:}
		\begin{itemize}
			\item On the $k$-th iteration choose a point $x_{k+1}$ from neighbourhood 
			of the current position $x_k$, such that
			\[
				\text{Obj}(x_{k+1}) < \text{Obj}(x_k)
			\]
			\item If there is no such point $x_{k+1}$ stop and return $x_k$
		\end{itemize}
	
		\vspace{0.2in}
		{\Large Problems:}
		\begin{itemize}
			\item How to choose the neighbourhood?
			\item How far will be the result from the solution?
		\end{itemize}
	
	\end{frame}


    \subsection{SDP relaxations}

        \begin{frame}{Semi-Definite-Programming}
            The following type of optimisation problems is considered to be the SDP problems:
            \begin{align*}
                \min_{x \in \mathbb{R}^n} &~c^Tx\\
                \text{s.t.} &~A_0 - x_1A_1 - \dots x_nA_n \succeq 0
            \end{align*}
            
        \end{frame}
        
        \begin{frame}{SDP relaxation}
        
            Suppose we have the initial problem:
            \[
                \min_{x \in X} f(x),
            \]
            where $X$ is a feasible region. If we construct the SDP problem with the $X'$ feasible region, s.t. $X \subseteq X'$, then this SDP problem is considered to be an SDP relaxation for the initial problem.
            
            %The quality of relaxation (for maximization problems) can be measured by the integrality gap:
            %\[
            %    \text{Integrality Gap} = \frac{\text{OPT} (\text{SDP})}{\text{OPT} (\text{Initial problem})} 
            %\]
            
        \end{frame}
	
	\begin{frame}{SDP relaxation for MaxCut}
	    The following optimisation problem represents the SDP relaxation for MaxCut
	    \begin{align*}
	        \min_X &~ \tr(WX),\\
	        \text{s.t.} &~ X \succeq 0,\\
	        &~ X_{ii} = 1 ~\forall i.
	    \end{align*}
	    Here $W$ is a matrix of weights.
	    
	    
	\end{frame}
        
        \begin{frame}{SDP relaxation with triangle constraints}
            In order to improve the SDP relaxation one can add triangle constraints like:
            \begin{align*}
                &x_{ij} + x_{jk} + x_{ki} \leq 2, \\
                &x_{ij} + x_{jk} \geq x_{ki}.
            \end{align*}
            Such constraints are appropriate for the cut problems on graphs.In these cases $x_{ij}$ could be:
            \[
                x_{ij} = \begin{cases} 1 & \text{if } (i, j) \text{ edge is in the cut,} \\ 
                0 & \text{otherwise.}\end{cases}
            \]
            
        \end{frame}

	\begin{frame}
		\frametitle{Interior Point Method}
		
		\begin{itemize}
			\item One can find solutions of SDP-relaxations via interior-point method
			\item Use log-det barrier function
		\end{itemize}
		
	\end{frame}
	
	\subsection{LP relaxations}
        \begin{frame}{LP relaxations}
            We want to implement \textbf{LP relaxations} for Maximal Cut, Min UnCut and Sparsest cut problems.
            
            \textbf{For example:} 
            
            MAXCUT can be phrased as the following integer program.
            \begin{align*}
                \max \sum\limits_{(u,v) \in E} e_{uv} \\
                x_u \in \{0,1\} \quad \forall u \in V\\
                e_{uv} \in \{0,1\} \quad \forall (u,v) \in E
            \end{align*}
            \begin{equation*}
                e_{uv} \le 
                \begin{cases}
                    x_u + x_v \\
                    2 - (x_u + x_v) \quad \forall (u,v) \in E
                \end{cases}
            \end{equation*}
            
        \end{frame}  
        
        \begin{frame}{LP relaxation for MAXCUT}
        
        We relax $e_{uv} \in \{0, 1\}$ to $0 \le e_{uv} \le 1$ and $x_{u,v} \in \{0, 1\}$ to $0 \le x_{u,v} \le 1$ to obtain the following LP relation.
            
            \begin{align*}
                \max \sum\limits_{(u,v) \in E} e_{uv} \\
                x_u \in [0,1] \quad \forall u \in V\\
                e_{uv} \in [0,1] \quad \forall (u,v) \in E
            \end{align*}
            \begin{equation*}
                e_{uv} \le 
                \begin{cases}
                    x_u + x_v \\
                    2 - (x_u + x_v) \quad \forall (u,v) \in E
                \end{cases}
            \end{equation*}
            
        \end{frame}   
        
    \subsection{First order methods}
        \begin{frame}{First order methods}
            We want to implement the following first order methods for SDP relaxations:
            \begin{enumerate}
                \item gradient descent;
                \item ADMM.
            \end{enumerate}
            
        \end{frame}
        
        \begin{frame}{Alternating direction method of multipliers}
            ADMM problem form (with f and g convex):
            \begin{align*}
                \min_{x, z} &~f(x) + g(z)\\
                \text{s.t.} &~Ax + Bz = c
            \end{align*}
            Augmented Lagrandian:
            \begin{align*}
                L_r(x,y,z)=f(z) + g(z) + y^{\top}(Ax + Bz - c) + \frac{r}{2}\| Ax + Bz - c\|^2_2
            \end{align*}
            ADMM:
            \begin{align*}
                x^{k+1}=\argmin_x L_r (x, z^k, y^k), \; \text{x - update},\\
                z^{k+1}=\argmin_z L_r (x^{k+1}, z, y^k), \; \text{z - update},\\
                y^{k+1}=y^k + r (Ax^{k+1} + Bz^{k+1} - c), \; \text{dual update}
            \end{align*}
            
        \end{frame}
		
	
	\begin{frame}
		\frametitle{}
		
		\begin{center}
			{\LARGE Thank you for attention!}
		\end{center}
		
	\end{frame}
	
	
	\begin{frame}{SDP relaxation for Sparsest cut Problem}
	    Let $x_e = \mathbb{I}\{e \in E'\}$ and $y_i$ represents whether or not the pair $(s_i, t_i)$ should be separated, then we have the following SDP relaxation:
	    \begin{align*}
	        \min &~t &\\
	        \text{s.t.}& &\\ 
	        &~ \begin{pmatrix} t & 1 \\ c^Tx & d^Ty \end{pmatrix} \succeq 0 &\\
	        &~ \sum_{e \in p} x_e \geq y_i,  &p \in \mathcal{P}_{s_i t_i} \\
	        &~ 1 \geq y_i \geq 0  &i \in \overline{1, k} \\
	        &~ 1\geq x_e \geq 0 & e \in E
	    \end{align*}
	\end{frame}

\end{document}
